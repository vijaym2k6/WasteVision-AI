{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8652790,"sourceType":"datasetVersion","datasetId":4905519},{"sourceId":13052847,"sourceType":"datasetVersion","datasetId":8265510}],"dockerImageVersionId":31091,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install ultralytics deep-sort-realtime opencv-python-headless pandas kaggle","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yaml_content = \"\"\"\ntrain: /kaggle/input/garbage-data/YOLO-Waste-Detection-1/YOLO-Waste-Detection-1/train/images\nval: /kaggle/input/garbage-data/YOLO-Waste-Detection-1/YOLO-Waste-Detection-1/valid/images\ntest: /kaggle/input/garbage-data/YOLO-Waste-Detection-1/YOLO-Waste-Detection-1/test/images\n\nnc: 5\nnames: ['Organic', 'Plastic', 'Paper', 'Metal', 'E-Waste']\n\"\"\"\n\nwith open(\"/kaggle/working/data.yaml\", \"w\") as f:\n    f.write(yaml_content)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(\"yolov8n.pt\")\nmodel.train(\n    data=\"/kaggle/working/data.yaml\",\n    epochs=25,\n    imgsz=544,\n    batch=12,\n    device=\"0,1\"   # âœ… use both GPUs\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nfrom ultralytics import YOLO\nfrom deep_sort_realtime.deepsort_tracker import DeepSort\nimport matplotlib.pyplot as plt\n\n# ðŸ”¹ Paths\nweights_path = \"/kaggle/working/runs/detect/train/weights/best.pt\"  # trained YOLO weights\nvideo_path = \"/kaggle/input/waste-input/waste_input.mp4\"           # input video\noutput_path = \"/kaggle/working/output_tracked.avi\"                 # output video\n\n# ðŸ”¹ Class names from your dataset\nclass_names = ['Organic', 'Plastic', 'Paper', 'Metal', 'E-Waste']\n\n# ðŸ”¹ Load YOLO model\nmodel = YOLO(weights_path)\n\n# ðŸ”¹ Initialize DeepSORT\ntracker = DeepSort(max_age=30, n_init=3, nms_max_overlap=1.0)\n\n# ðŸ”¹ Open video and output writer\ncap = cv2.VideoCapture(video_path)\nw = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfps = cap.get(cv2.CAP_PROP_FPS)\n\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nout = cv2.VideoWriter(output_path, fourcc, fps, (w, h))\n\nwhile cap.isOpened():\n    ret, frame = cap.read()\n    if not ret:\n        break\n\n    # Run YOLO detection\n    results = model.predict(frame, imgsz=640, conf=0.5, verbose=False)\n\n    detections = []\n    for r in results:\n        for box in r.boxes:\n            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n            conf = float(box.conf[0])\n            cls = int(box.cls[0])\n            detections.append([[x1, y1, x2-x1, y2-y1], conf, cls])\n\n    # Update DeepSORT tracker\n    tracks = tracker.update_tracks(detections, frame=frame)\n\n    # Draw boxes with class name + track ID\n    for track in tracks:\n        if not track.is_confirmed():\n            continue\n        x1, y1, x2, y2 = track.to_ltrb()\n        track_id = track.track_id\n        \n        # Assign class name from detection\n        cls_name = class_names[track.det_class] if hasattr(track, 'det_class') else 'Unknown'\n        \n        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,255,0), 2)\n        cv2.putText(frame, f\"{cls_name} ID {track_id}\", (int(x1), int(y1)-10),\n                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,0), 2)\n\n    out.write(frame)\n\ncap.release()\nout.release()\n\nprint(f\"âœ… Tracking finished. Saved at: {output_path}\")\n\n# ðŸ”¹ Display a sample frame\ncap = cv2.VideoCapture(output_path)\nret, frame = cap.read()\ncap.release()\nif ret:\n    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    plt.axis(\"off\")\n    plt.title(\"Sample Output Frame\")\n    plt.show()\n\n# ðŸ”¹ Create download link in Kaggle\nfrom IPython.display import FileLink\nFileLink(output_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}